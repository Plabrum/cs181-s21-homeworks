{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EM_Geometric(object):\n",
    "    def __init__(self, num_clusters, min_step=1e-4, probs=None, priors=None):\n",
    "        '''\n",
    "        Initialize the EM algorithm based on given parameters\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_clusters : int\n",
    "            The number of labels the EM algorithm should form clusters for\n",
    "        min_step : int\n",
    "            The minimum steps required for termination of the algorithm\n",
    "        probs : np.array\n",
    "            The initial parameter p for each label (geometric distribution)\n",
    "        priors : np.array\n",
    "            The initial mixing proportion of each label (aka theta)\n",
    "        '''\n",
    "        self.num_clusters = num_clusters\n",
    "        self.min_step = min_step\n",
    "\n",
    "        if probs is None:\n",
    "            self.probs = np.random.random(self.num_clusters)\n",
    "        else:\n",
    "            self.probs = probs\n",
    "\n",
    "        if priors is None:\n",
    "            self.pis = np.ones(self.num_clusters) / self.num_clusters\n",
    "        else:\n",
    "            self.pis = priors\n",
    "\n",
    "    def cluster(self, data, max_iters=50):\n",
    "        '''\n",
    "        Train on the given data to form clusters for the labels\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame is it?\n",
    "            The feature values of the data set\n",
    "        '''\n",
    "        self.data = data\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Initialize the soft cluster assignments q for each data point to each label\n",
    "        # np.matrix was depreciated, use np array instead?\n",
    "        self.q = np.asarray(np.empty((len(self.data), self.num_clusters), dtype=float))\n",
    "\n",
    "        num_iters = 0\n",
    "\n",
    "        # Current and previous log-likelihoods\n",
    "        curr_ll = 0\n",
    "        prev_ll = 0\n",
    "\n",
    "        # While termination conditions have not been met, run the algorithm\n",
    "        while num_iters <= 1 or (curr_ll - prev_ll > self.min_step and num_iters < max_iters):\n",
    "            # Perform the expectation step\n",
    "            self.e_step()\n",
    "            # Perform the maximization step\n",
    "            self.m_step()\n",
    "\n",
    "            num_iters += 1\n",
    "\n",
    "            # Calculate and compare log-likelihoods\n",
    "            prev_ll = curr_ll\n",
    "            curr_ll = self.loglikelihood()\n",
    "            print(f'Iteration {num_iters}, log-likelihood: {curr_ll}')\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f'Complete, time elapsed: {total_time} seconds')\n",
    "\n",
    "        # Sort the clusters and re-arrange the soft labels\n",
    "        i = np.argsort(self.probs)\n",
    "        self.probs = np.sort(self.probs)\n",
    "        self.q = self.q[:, i]\n",
    "    \n",
    "    def pmf(self, x, p):\n",
    "        # each x for a given n, each p for a given k\n",
    "        return np.power((1-p), x - 1)*p\n",
    "\n",
    "    def loglikelihood(self):\n",
    "        '''\n",
    "        Calculate the current log-likelihood given data and soft assignments\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ll : float\n",
    "            The log-likelihood of current set of labels (according to a geometric distribution)\n",
    "        '''\n",
    "\n",
    "        N, K = self.q.shape\n",
    "        z = self.q\n",
    "        x = self.data\n",
    "        p = self.probs\n",
    "        theta = self.pis\n",
    "        \n",
    "        loss_list = []\n",
    "        for n in range(N):\n",
    "            for k in range(K):\n",
    "                loss_list.append( z[n][k] * np.log(self.pmf(x[n],p[k]) * theta[k]) )\n",
    "\n",
    "        return sum(loss_list)\n",
    "\n",
    "    def e_step(self):\n",
    "        '''\n",
    "        Run the expectation step, calculating the soft assignments based on current parameter estimates\n",
    "        '''\n",
    "        N, K = self.q.shape\n",
    "        z = self.q\n",
    "        x = self.data\n",
    "        p = self.probs\n",
    "        theta = self.pis\n",
    "\n",
    "        for n in range(N):\n",
    "            row = np.array([self.pmf(self.data[n], self.probs[k])*self.pis[k] for k in range(K)])\n",
    "            self.q[n] = row/np.sum(row)\n",
    "            assert(np.round(np.sum(self.q[n]), 2) == 1.0)\n",
    "        \n",
    "        # print(\"sum of qs: \", np.sum(self.q, axis=1))\n",
    "\n",
    "    def m_step(self):\n",
    "        '''\n",
    "        Run the maximization step, calculating parameter estimates based on current soft assignments\n",
    "        '''\n",
    "        self.pis = np.sum(self.q, axis=0) / len(self.q)\n",
    "        self.probs = (np.sum(self.q, axis=0) / np.dot(self.q.T, self.data)).flatten()\n",
    "        print(\"sum of probs:\", np.sum(self.probs))\n",
    "        # assert(np.round(np.sum(self.probs), 2) == 1.0)\n",
    "\n",
    "    def get_labels(self):\n",
    "        '''\n",
    "        Return the label with highest probability among the soft assignments for each data point\n",
    "        '''\n",
    "        return np.array([np.argmax(q) for q in np.array(self.q)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_geom_data(num_data, cluster_probs):\n",
    "    '''\n",
    "    Generate an equal number of data points for each cluster, based on geometric distribution\n",
    "    '''\n",
    "    data = np.array([])\n",
    "    labels = np.array([], dtype=int)\n",
    "    for i, prob in enumerate(cluster_probs):\n",
    "        data = np.concatenate((data, np.random.geometric(p=prob, size=num_data)))\n",
    "        labels = np.concatenate((labels, np.full(num_data, i, dtype=int)))\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sum of probs: 1.494746913852226\nIteration 1, log-likelihood: -79.90681972945238\nsum of probs: 1.5097528057204757\nIteration 2, log-likelihood: -78.07387058639466\nsum of probs: 1.5018006868616973\nIteration 3, log-likelihood: -77.40320755425566\nsum of probs: 1.4897644172796956\nIteration 4, log-likelihood: -77.01714311245175\nsum of probs: 1.478836027396533\nIteration 5, log-likelihood: -76.67373510359023\nsum of probs: 1.470225486515476\nIteration 6, log-likelihood: -76.3317603084892\nsum of probs: 1.464114426585778\nIteration 7, log-likelihood: -75.99586061479391\nsum of probs: 1.4603906004162712\nIteration 8, log-likelihood: -75.67592413942634\nsum of probs: 1.4588298656870637\nIteration 9, log-likelihood: -75.37823466689731\nsum of probs: 1.4591574642786855\nIteration 10, log-likelihood: -75.10469404755496\nsum of probs: 1.4610821400047092\nIteration 11, log-likelihood: -74.85399874156823\nsum of probs: 1.4643191556431414\nIteration 12, log-likelihood: -74.62307433227629\nsum of probs: 1.4686044436715537\nIteration 13, log-likelihood: -74.40823796449057\nsum of probs: 1.4737013174420943\nIteration 14, log-likelihood: -74.20596384114003\nsum of probs: 1.479401848208143\nIteration 15, log-likelihood: -74.01329609160578\nsum of probs: 1.4855251272758676\nIteration 16, log-likelihood: -73.82800836873588\nsum of probs: 1.4919142203393174\nIteration 17, log-likelihood: -73.64860680229806\nsum of probs: 1.4984330181266443\nIteration 18, log-likelihood: -73.47424893522019\nsum of probs: 1.5049636263370743\nIteration 19, log-likelihood: -73.30462572025921\nsum of probs: 1.5114045152341404\nIteration 20, log-likelihood: -73.13983401160874\nsum of probs: 1.5176693771026248\nIteration 21, log-likelihood: -72.98025418495268\nsum of probs: 1.5236864938934565\nIteration 22, log-likelihood: -72.82644006485862\nsum of probs: 1.5293983652537602\nIteration 23, log-likelihood: -72.67902435816349\nsum of probs: 1.5347613589380296\nIteration 24, log-likelihood: -72.5386407882321\nsum of probs: 1.5397451966737064\nIteration 25, log-likelihood: -72.4058631059492\nsum of probs: 1.5443321590838122\nIteration 26, log-likelihood: -72.28116054510294\nsum of probs: 1.54851596757205\nIteration 27, log-likelihood: -72.16486880669191\nsum of probs: 1.5523003673010762\nIteration 28, log-likelihood: -72.0571751928755\nsum of probs: 1.5556974854975478\nIteration 29, log-likelihood: -71.95811606469819\nsum of probs: 1.5587260691124558\nIteration 30, log-likelihood: -71.86758441761097\nsum of probs: 1.561409714914611\nIteration 31, log-likelihood: -71.78534511796224\nsum of probs: 1.563775196217415\nIteration 32, log-likelihood: -71.71105527028608\nsum of probs: 1.5658509687519424\nIteration 33, log-likelihood: -71.64428730588143\nsum of probs: 1.5676659098243568\nIteration 34, log-likelihood: -71.58455267772672\nsum of probs: 1.5692483156339903\nIteration 35, log-likelihood: -71.531324465489\nsum of probs: 1.570625155948361\nIteration 36, log-likelihood: -71.48405767251269\nsum of probs: 1.5718215658782468\nIteration 37, log-likelihood: -71.44220647052217\nsum of probs: 1.5728605421294626\nIteration 38, log-likelihood: -71.40523806710485\nsum of probs: 1.5737628053109902\nIteration 39, log-likelihood: -71.37264320519624\nsum of probs: 1.5745467893165834\nIteration 40, log-likelihood: -71.34394354174523\nsum of probs: 1.575228721839147\nIteration 41, log-likelihood: -71.31869629902687\nsum of probs: 1.5758227651804797\nIteration 42, log-likelihood: -71.29649665109008\nsum of probs: 1.5763411924378976\nIteration 43, log-likelihood: -71.27697831825778\nsum of probs: 1.576794580006906\nIteration 44, log-likelihood: -71.25981281329615\nsum of probs: 1.5771920026038566\nIteration 45, log-likelihood: -71.2447077302061\nsum of probs: 1.5775412214278208\nIteration 46, log-likelihood: -71.23140440337534\nsum of probs: 1.5778488595833822\nIteration 47, log-likelihood: -71.21967520009628\nsum of probs: 1.5781205615309324\nIteration 48, log-likelihood: -71.20932064896124\nsum of probs: 1.578361135235108\nIteration 49, log-likelihood: -71.20016655353739\nsum of probs: 1.578574676983471\nIteration 50, log-likelihood: -71.19206119627239\nComplete, time elapsed: 0.14359307289123535 seconds\nFinal probabilities: [0.07814226 0.50061351 0.99981891]\nAccuracy: 0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Toggle these between 10 / 1000 and [0.1, 0.5, 0.9] / [0.1, 0.2, 0.9]\n",
    "num_data = 10\n",
    "cluster_probs = [0.1, 0.5, 0.9]\n",
    "\n",
    "# Do not edit the below code, it is to help you run the algorithm\n",
    "# -------------------------------------------------------------------------------\n",
    "data, labels = generate_geom_data(num_data=num_data, cluster_probs=cluster_probs)\n",
    "\n",
    "em_algo = EM_Geometric(num_clusters=3)\n",
    "em_algo.cluster(data)\n",
    "print(f'Final probabilities: {em_algo.probs}')\n",
    "\n",
    "accuracy = np.equal(em_algo.get_labels(), labels).sum() / len(labels)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.32514885, 0.31155925, 0.3632919 ])"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "np.sum(em_algo.q, axis=0)/len(em_algo.q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}